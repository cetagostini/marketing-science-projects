{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predictive_ads_analytics_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUvPiSgJFmqs"
      },
      "source": [
        "The following document has information about my process of experimenting with various models to solve a classification problem, in which I tested different models of supervised and unsupervised learning. Which then save in a file to be consumed after training.\n",
        "\n",
        "As it is a proof of concept the code is not ordered and neither optimized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t77mMt2GjBXY"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from os import walk\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_tree\n",
        "\n",
        "import joblib\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGe57XEEilWj"
      },
      "source": [
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'credentials.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXumsg5wjBto"
      },
      "source": [
        "query_url = \"\"\"\n",
        "\n",
        "WITH urls_main_table AS (\n",
        "    SELECT \n",
        "    source,   \n",
        "    ad_id,   \n",
        "    image_asset_url as url\n",
        "    FROM `omg-latam-prd-adh-datahouse-cl.clients_table.main_url_dh`\n",
        "    where source = 'Facebook ads' and image_asset_url != '0'\n",
        "    group by 1,2,3  \n",
        "\n",
        "    UNION ALL \n",
        "\n",
        "    SELECT \n",
        "    source,   \n",
        "    ad_id,   \n",
        "    promoted_tweet_card_image_url as url\n",
        "    FROM `omg-latam-prd-adh-datahouse-cl.clients_table.main_url_dh`\n",
        "    where source = 'Twitter ads' and promoted_tweet_card_image_url != '0'\n",
        "    group by 1,2,3  \n",
        "\n",
        "),\n",
        "\n",
        "ad_values AS (\n",
        "    SELECT date,\n",
        "    ad_id, spend, post_engagements as clicks\n",
        "    FROM `main_views_tables.main_ad`\n",
        "    where regexp_contains(account_name, '(?i).*scoti.*')\n",
        "),\n",
        "\n",
        "spend_average AS (\n",
        "    select ad_id, avg(spend) as avg_spend, avg(post_engagements) as avg_clicks from `main_views_tables.main_ad`\n",
        "    group by 1\n",
        "),\n",
        "\n",
        "categorical_feats AS (\n",
        "\n",
        "    SELECT ad_id, main_topic, main_color, locale, second_topic, second_color, third_topic, third_color\n",
        "    FROM `clients_table.main_categorical_values`\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "SELECT \n",
        "\n",
        "date, source, url, e.ad_id,\n",
        "main_topic, main_color, locale, second_topic, second_color, third_topic, third_color,\n",
        "\n",
        "(CASE \n",
        "WHEN spend >= avg_spend THEN 1\n",
        "WHEN spend < avg_spend THEN 0\n",
        "END) as over_avg_spend, \n",
        "\n",
        "(CASE \n",
        "WHEN clicks >= avg_clicks THEN 1\n",
        "WHEN clicks < avg_clicks THEN 0\n",
        "END) as over_avg_clicks\n",
        "\n",
        "FROM\n",
        "(SELECT\n",
        "date, source, url, c.ad_id,\n",
        "main_topic, main_color, locale, second_topic, second_color, third_topic, third_color, spend, clicks\n",
        "FROM (SELECT date,\n",
        "a.source, a.url, b.ad_id, b.spend, b.clicks\n",
        "FROM urls_main_table a\n",
        "RIGHT JOIN ad_values b\n",
        "ON a.ad_id = b.ad_id) c\n",
        "\n",
        "INNER JOIN categorical_feats d\n",
        "\n",
        "ON c.ad_id = d.ad_id) e\n",
        "\n",
        "INNER JOIN spend_average f\n",
        "ON e.ad_id = f.ad_id\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "dataframe = pd.read_gbq(query_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsOvtoWc2oTF"
      },
      "source": [
        "dataframe = dataframe[['main_topic', 'main_color', 'second_topic', 'second_color', 'third_topic', 'third_color', 'locale', 'over_avg_spend', 'over_avg_clicks']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "16jMMZuh39i6",
        "outputId": "6b08a996-5060-4d1f-e529-6e7ea894c8e1"
      },
      "source": [
        "vars = ['main_topic', 'main_color', 'second_topic', 'second_color', 'third_topic', 'third_color', 'locale']\n",
        "\n",
        "for var in vars:\n",
        "  cat_list = 'var' + '_' + var\n",
        "  cat_list = pd.get_dummies(dataframe[var], prefix= var)\n",
        "  dataframe1 = dataframe.join(cat_list)\n",
        "  dataframe = dataframe1\n",
        "\n",
        "dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>main_topic</th>\n",
              "      <th>main_color</th>\n",
              "      <th>second_topic</th>\n",
              "      <th>second_color</th>\n",
              "      <th>third_topic</th>\n",
              "      <th>third_color</th>\n",
              "      <th>locale</th>\n",
              "      <th>over_avg_spend</th>\n",
              "      <th>over_avg_clicks</th>\n",
              "      <th>main_topic_Arm</th>\n",
              "      <th>main_topic_Chin</th>\n",
              "      <th>main_topic_Clothing</th>\n",
              "      <th>main_topic_Eyelash</th>\n",
              "      <th>main_topic_Forehead</th>\n",
              "      <th>main_topic_Glasses</th>\n",
              "      <th>main_topic_Hair</th>\n",
              "      <th>main_topic_Hand</th>\n",
              "      <th>main_topic_Head</th>\n",
              "      <th>main_topic_Jaw</th>\n",
              "      <th>main_topic_Laptop</th>\n",
              "      <th>main_topic_Mobilephone</th>\n",
              "      <th>main_topic_Plant</th>\n",
              "      <th>main_topic_Shorts</th>\n",
              "      <th>main_topic_Sleeve</th>\n",
              "      <th>main_topic_Smile</th>\n",
              "      <th>main_topic_Table</th>\n",
              "      <th>main_topic_Tire</th>\n",
              "      <th>main_topic_video</th>\n",
              "      <th>main_color_black</th>\n",
              "      <th>main_color_cadetblue</th>\n",
              "      <th>main_color_darkolivegreen</th>\n",
              "      <th>main_color_darkslategray</th>\n",
              "      <th>main_color_dimgray</th>\n",
              "      <th>main_color_dodgerblue</th>\n",
              "      <th>main_color_hotpink</th>\n",
              "      <th>main_color_linen</th>\n",
              "      <th>main_color_mediumpurple</th>\n",
              "      <th>main_color_sienna</th>\n",
              "      <th>main_color_skyblue</th>\n",
              "      <th>main_color_yellowgreen</th>\n",
              "      <th>...</th>\n",
              "      <th>second_color_slategray</th>\n",
              "      <th>third_topic_Beard</th>\n",
              "      <th>third_topic_Cap</th>\n",
              "      <th>third_topic_Chin</th>\n",
              "      <th>third_topic_Eyelash</th>\n",
              "      <th>third_topic_Eyewear</th>\n",
              "      <th>third_topic_Flashphotography</th>\n",
              "      <th>third_topic_Font</th>\n",
              "      <th>third_topic_Furniture</th>\n",
              "      <th>third_topic_Gesture</th>\n",
              "      <th>third_topic_Jaw</th>\n",
              "      <th>third_topic_Jersey</th>\n",
              "      <th>third_topic_Landvehicle</th>\n",
              "      <th>third_topic_Organism</th>\n",
              "      <th>third_topic_Outerwear</th>\n",
              "      <th>third_topic_Personalcomputer</th>\n",
              "      <th>third_topic_Skin</th>\n",
              "      <th>third_topic_Sleeve</th>\n",
              "      <th>third_topic_Smile</th>\n",
              "      <th>third_topic_Sportsuniform</th>\n",
              "      <th>third_topic_Tabletcomputer</th>\n",
              "      <th>third_topic_Tableware</th>\n",
              "      <th>third_color_black</th>\n",
              "      <th>third_color_crimson</th>\n",
              "      <th>third_color_darkgray</th>\n",
              "      <th>third_color_darkslategray</th>\n",
              "      <th>third_color_dimgray</th>\n",
              "      <th>third_color_gray</th>\n",
              "      <th>third_color_lightgray</th>\n",
              "      <th>third_color_maroon</th>\n",
              "      <th>third_color_mistyrose</th>\n",
              "      <th>third_color_silver</th>\n",
              "      <th>third_color_slateblue</th>\n",
              "      <th>third_color_slategray</th>\n",
              "      <th>third_color_tan</th>\n",
              "      <th>locale_en</th>\n",
              "      <th>locale_error</th>\n",
              "      <th>locale_es</th>\n",
              "      <th>locale_fr</th>\n",
              "      <th>locale_no_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Arm</td>\n",
              "      <td>dodgerblue</td>\n",
              "      <td>Shirt</td>\n",
              "      <td>skyblue</td>\n",
              "      <td>Smile</td>\n",
              "      <td>lightgray</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Smile</td>\n",
              "      <td>mediumpurple</td>\n",
              "      <td>Product</td>\n",
              "      <td>black</td>\n",
              "      <td>Sleeve</td>\n",
              "      <td>slateblue</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Table</td>\n",
              "      <td>hotpink</td>\n",
              "      <td>Fashion</td>\n",
              "      <td>darkgray</td>\n",
              "      <td>Tableware</td>\n",
              "      <td>mistyrose</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>video</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>error</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Laptop</td>\n",
              "      <td>cadetblue</td>\n",
              "      <td>Product</td>\n",
              "      <td>seagreen</td>\n",
              "      <td>Cap</td>\n",
              "      <td>gray</td>\n",
              "      <td>en</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16489</th>\n",
              "      <td>Chin</td>\n",
              "      <td>black</td>\n",
              "      <td>Jaw</td>\n",
              "      <td>darkslategray</td>\n",
              "      <td>Beard</td>\n",
              "      <td>darkslategray</td>\n",
              "      <td>es</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16490</th>\n",
              "      <td>Chin</td>\n",
              "      <td>black</td>\n",
              "      <td>Jaw</td>\n",
              "      <td>darkslategray</td>\n",
              "      <td>Beard</td>\n",
              "      <td>darkslategray</td>\n",
              "      <td>es</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16491</th>\n",
              "      <td>Chin</td>\n",
              "      <td>black</td>\n",
              "      <td>Jaw</td>\n",
              "      <td>darkslategray</td>\n",
              "      <td>Beard</td>\n",
              "      <td>darkslategray</td>\n",
              "      <td>es</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16492</th>\n",
              "      <td>Chin</td>\n",
              "      <td>black</td>\n",
              "      <td>Jaw</td>\n",
              "      <td>darkslategray</td>\n",
              "      <td>Beard</td>\n",
              "      <td>darkslategray</td>\n",
              "      <td>es</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16493</th>\n",
              "      <td>Chin</td>\n",
              "      <td>black</td>\n",
              "      <td>Jaw</td>\n",
              "      <td>darkslategray</td>\n",
              "      <td>Beard</td>\n",
              "      <td>darkslategray</td>\n",
              "      <td>es</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16494 rows Ã— 113 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      main_topic    main_color  ... locale_fr locale_no_text\n",
              "0            Arm    dodgerblue  ...         0              0\n",
              "1          Smile  mediumpurple  ...         0              0\n",
              "2          Table       hotpink  ...         0              0\n",
              "3          video          None  ...         0              0\n",
              "4         Laptop     cadetblue  ...         0              0\n",
              "...          ...           ...  ...       ...            ...\n",
              "16489       Chin         black  ...         0              0\n",
              "16490       Chin         black  ...         0              0\n",
              "16491       Chin         black  ...         0              0\n",
              "16492       Chin         black  ...         0              0\n",
              "16493       Chin         black  ...         0              0\n",
              "\n",
              "[16494 rows x 113 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG9YWaRf1utv"
      },
      "source": [
        "data_vars = dataframe.columns.values.tolist()\n",
        "to_keep = [i for i in data_vars if i not in vars]\n",
        "\n",
        "data_final = dataframe[to_keep]\n",
        "data_final.columns.values\n",
        "\n",
        "data_final_vars = data_final.columns.values.tolist()\n",
        "v_y = ['over_avg_clicks']\n",
        "v_x = [i for i in data_final_vars if i not in v_y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z78w7Cu12RNn"
      },
      "source": [
        "X = dataframe[v_x]\n",
        "y = dataframe[v_y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Keg7pTCY3F8k"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 40, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG5Xv1l8QVdl"
      },
      "source": [
        "model_xgb = xgb.XGBClassifier(objective = 'binary:logistic', n_estimators = 105, max_depth=75, seed = 10, reg_alpha=7)\n",
        "model_xgb.fit(X_train.values, y_train.values.ravel())\n",
        "y_pred = model_xgb.predict(X_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nVwCemSQcc_",
        "outputId": "fce9069b-55b2-49ef-f7e0-56d6a1f6d774"
      },
      "source": [
        "print('Area debajo de la curva:', roc_auc_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('accuracy:', round(accuracy_score(y_test, y_pred), 2))\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area debajo de la curva: 0.9986280487804878\n",
            "Recall: 0.9972560975609757\n",
            "Precision: 1.0\n",
            "accuracy: 1.0\n",
            "[[  38    0]\n",
            " [  18 6542]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4TwQMvARiuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "92ec9b11-6f41-42de-a17d-6a92b3bf183e"
      },
      "source": [
        "base_frame = dict.fromkeys(list(X_train.columns), [0])\n",
        "\n",
        "main_topic = 'Clothing' #@param ['Table', 'Smile','Laptop', 'video', 'Arm', 'Hair', 'Jaw', 'Forehead','Head','Chin','Clothing','Sleeve','Plant','Tire', 'Eyelash','Hand', 'Mobilephone', 'Glasses','Shorts']\n",
        "second_topic = 'Jaw' #@param ['Jaw', 'Product', 'Flashphotography', 'Sleeve', 'Beard', 'Computer', 'Glasses', 'Visioncare', 'Fashion', 'Shirt', 'Jeans', 'Wheel', 'Jersey', 'Smile', 'CommunicationDevice', 'Plant', 'Mobilephone', 'Green', 'Chin', 'Human']\n",
        "third_topic = 'Font' #@param ['Beard', 'Font', 'Jersey', 'Jaw', 'Chin', 'Eyewear', 'Sleeve', 'Cap', 'Smile', 'Tableware', 'Personalcomputer', 'Eyelash', 'Skin',  'Landvehicle', 'Tabletcomputer', 'Gesture', 'Organism', 'Outerwear', 'Flashphotography', 'Sportsuniform', 'Furniture']\n",
        "\n",
        "locale = 'en' #@param ['es', 'en']\n",
        "\n",
        "main_color = 'skyblue' #@param ['black', 'darkslategray', 'darkolivegreen', 'cadetblue', 'dodgerblue', 'mediumpurple', 'hotpink', 'skyblue', 'dimgray', 'linen', 'yellowgreen', 'sienna']\n",
        "second_color = 'darkgray' #@param ['darkslategray', 'dimgray', 'black', 'darkgray', 'seagreen','skyblue', 'maroon', 'paleturquoise', 'silver', 'crimson','darkgreen', 'slategray', 'mediumpurple', 'gray']\n",
        "third_color = 'lightgray' #@param ['darkslategray', 'slateblue', 'lightgray', 'mistyrose', 'gray', 'maroon', 'black', 'tan', 'darkgray', 'crimson', 'slategray', 'dimgray', 'silver']\n",
        "\n",
        "over_avg_spend = 'False' #@param ['True', 'False']\n",
        "if over_avg_spend == 'False':\n",
        "  over_avg_spend = 0\n",
        "else:\n",
        "  over_avg_spend = 1\n",
        "\n",
        "dataframe = pd.DataFrame({'main_topic':[main_topic], 'main_color':[main_color], 'second_topic':[second_topic], 'second_color':[second_color], \n",
        "                          'third_topic':[third_topic], 'third_color':[third_color], 'locale':[locale], 'over_avg_spend':[over_avg_spend]})\n",
        "\n",
        "vars = ['main_topic', 'main_color', 'second_topic', 'second_color', 'third_topic', 'third_color', 'locale']\n",
        "\n",
        "for var in vars:\n",
        "  cat_list = 'var' + '_' + var\n",
        "  cat_list = pd.get_dummies(dataframe[var], prefix= var)\n",
        "  dataframe1 = dataframe.join(cat_list)\n",
        "  dataframe = dataframe1\n",
        "\n",
        "data_vars = dataframe.columns.values.tolist()\n",
        "to_keep = [i for i in data_vars if i not in vars]\n",
        "\n",
        "data_final = dataframe[to_keep]\n",
        "my_dict_frame = data_final.to_dict('records')\n",
        "\n",
        "base_frame.update(my_dict_frame[0])\n",
        "to_predict_frame = pd.DataFrame(base_frame)\n",
        "\n",
        "result = model_xgb.predict(to_predict_frame.values)\n",
        "result_prob = model_xgb.predict_proba(to_predict_frame.values)\n",
        "\n",
        "print('If the ad can be above the average of the results studied it will be classified as 1, otherwise it will be classified as 0. \\nThe classification of the ad model entered is: {}'.format(result))\n",
        "\n",
        "print('Probability of not being successful according to the given parameters: {}%'.format(result_prob[0][0] * 100),\n",
        "      '\\nProbability of success according to the given parameters: {}%'.format(result_prob[0][1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "If the ad can be above the average of the results studied it will be classified as 1, otherwise it will be classified as 0. \n",
            "The classification of the ad model entered is: [1]\n",
            "Probability of not being successful according to the given parameters: 0.09180307388305664% \n",
            "Probability of success according to the given parameters: 99.90819692611694%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJenplOPaGEg"
      },
      "source": [
        "plot_tree(model_xgb, num_trees=75)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FinyV1c-Bzc2"
      },
      "source": [
        "### FIRST MDOEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUU74jaJ4LBI",
        "outputId": "e899cd0f-491f-426b-c904-43d34fe50987"
      },
      "source": [
        "model_classifier = Sequential()\n",
        "\n",
        "input_dimension = len(v_x)\n",
        "layers = 6\n",
        "neurons = 16\n",
        "output_layer = 1\n",
        "\n",
        "for layer in range(layers):\n",
        "  model_classifier.add(Dense(neurons, activation= 'relu', kernel_initializer= 'random_normal'))\n",
        "  \n",
        "  if layer == layers-1:\n",
        "    model_classifier.add(Dense(output_layer, activation= 'sigmoid', kernel_initializer='random_normal'))\n",
        "\n",
        "define_optimizer = keras.optimizers.Adam(lr = 0.01)\n",
        "model_classifier.compile(optimizer = define_optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "history_values = model_classifier.fit(x = X_train.values, y = y_train.values, batch_size = 15, epochs = 350, validation_split = 0.15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "557/557 [==============================] - 2s 3ms/step - loss: 0.1190 - accuracy: 0.9796 - val_loss: 0.0056 - val_accuracy: 0.9959\n",
            "Epoch 2/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0071 - accuracy: 0.9937 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 3/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.0046 - val_accuracy: 0.9973\n",
            "Epoch 4/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9973\n",
            "Epoch 5/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0046 - val_accuracy: 0.9973\n",
            "Epoch 6/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 7/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 8/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 9/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 10/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 11/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 12/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 13/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 14/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 15/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 16/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 17/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 18/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 19/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 20/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 21/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 22/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9966 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 23/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9974 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 24/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0065 - accuracy: 0.9967 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 25/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 26/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 27/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9966 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 28/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 29/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 30/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9971 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 31/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 32/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 33/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0067 - accuracy: 0.9966 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 34/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 35/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9967 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 36/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 37/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9973 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 38/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 39/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 40/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9970 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 41/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 42/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 43/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 44/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 45/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 46/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 47/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9968 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 48/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 49/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 50/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 51/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 52/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 53/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 54/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 55/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 56/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 57/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 58/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 59/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9970 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 60/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9979 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 61/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 62/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 63/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 64/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 65/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0064 - accuracy: 0.9968 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 66/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9967 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 67/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 68/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 69/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 70/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.9962 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 71/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 72/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 73/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 74/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 75/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 76/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 77/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 78/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 79/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 80/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 81/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 82/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0067 - accuracy: 0.9965 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 83/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 84/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 85/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 86/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9971 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 87/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 88/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 89/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 90/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 91/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 92/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 93/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 94/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0063 - accuracy: 0.9965 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 95/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 96/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 97/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 98/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 99/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 100/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9973 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 101/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 102/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 103/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 104/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 105/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 106/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 107/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 108/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 109/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9969 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 110/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 111/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9977 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 112/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 113/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 114/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 115/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0065 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 116/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 117/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 118/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9970 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 119/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 120/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 121/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 122/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 123/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9971 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 124/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0067 - accuracy: 0.9958 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 125/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 126/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 127/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9969 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 128/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9967 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 129/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9973 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 130/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 131/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 132/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 133/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 134/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 135/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 136/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 137/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9972 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 138/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 139/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 140/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 141/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9968 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 142/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9971 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 143/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 144/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 145/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 146/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 147/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 148/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 149/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 150/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9977 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 151/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 152/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9967 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 153/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 154/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 155/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 156/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 157/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 158/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 159/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 160/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 161/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9971 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 162/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 163/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 164/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9973 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 165/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 166/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9973 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 167/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 168/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 169/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 170/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 171/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 172/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 173/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 174/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 175/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 176/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 177/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 178/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 179/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 180/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 181/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 182/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 183/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 184/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9973 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 185/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 186/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 187/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 188/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 189/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 190/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 191/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 192/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9973 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 193/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 194/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 195/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 196/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 197/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 198/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 199/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 200/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 201/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9973 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 202/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 203/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0058 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 204/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 205/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 206/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 207/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 208/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 209/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 210/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 211/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 212/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 213/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9974 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 214/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 215/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 216/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9974 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 217/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 218/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 219/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 220/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 221/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9971 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 222/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 223/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 224/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 225/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 226/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 227/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 228/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 229/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 230/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 231/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 232/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 233/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 234/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0063 - accuracy: 0.9969 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 235/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 236/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 237/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 238/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0058 - accuracy: 0.9970 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 239/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 240/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 241/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 242/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 243/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 244/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 245/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9969 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 246/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 247/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 248/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 249/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9968 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 250/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 251/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 252/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 253/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 254/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0069 - accuracy: 0.9968 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 255/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 256/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 257/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 258/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 259/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9971 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 260/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 261/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 262/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 263/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9969 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 264/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 265/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 266/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 267/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 268/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9967 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 269/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 270/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 271/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 272/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 273/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9975 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 274/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 275/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 276/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 277/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 278/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 279/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 280/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 281/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9974 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 282/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 283/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 284/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0058 - accuracy: 0.9968 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 285/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9973 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 286/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 287/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 288/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9973 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 289/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 290/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 291/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 292/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 293/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 294/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 295/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 296/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 297/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9969 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 298/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 299/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 300/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 301/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 302/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 303/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0068 - accuracy: 0.9960 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 304/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0058 - accuracy: 0.9973 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 305/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 306/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9967 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 307/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 308/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 309/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9967 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 310/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 311/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 312/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 313/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 314/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 315/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9973 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 316/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 317/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9975 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 318/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0069 - accuracy: 0.9967 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 319/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 320/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 321/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0058 - accuracy: 0.9971 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 322/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 0.9979 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 323/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9971 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 324/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 325/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 326/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 327/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 328/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 329/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9967 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 330/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 331/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9970 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 332/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 333/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 334/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.0049 - val_accuracy: 0.9973\n",
            "Epoch 335/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 336/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.9962 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 337/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 338/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 339/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 340/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 341/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 342/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 343/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9974 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 344/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 345/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9978 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 346/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9973\n",
            "Epoch 347/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 348/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9977 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 349/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9973\n",
            "Epoch 350/350\n",
            "557/557 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofbQQWE85rIW",
        "outputId": "24b6e1ec-27c8-45da-eec5-76dd4842762c"
      },
      "source": [
        "model_classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                1696      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 3,073\n",
            "Trainable params: 3,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGtR1kmR5s77",
        "outputId": "0c432305-dc4b-42bd-b144-8cb01794a90e"
      },
      "source": [
        "evaluation_model = model_classifier.evaluate(X_train, y_train)\n",
        "print(evaluation_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "308/308 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.9977\n",
            "[0.004854610655456781, 0.9976599812507629]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUYHTQY050ob"
      },
      "source": [
        "y_pred = model_classifier.predict(X_test).ravel()\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEHDKNvYZQzK",
        "outputId": "a520c798-73f0-4a4e-97c1-a9ef4f000625"
      },
      "source": [
        "print('Area debajo de la curva:', roc_auc_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('accuracy:', round(accuracy_score(y_test, y_pred), 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area debajo de la curva: 0.9980813507290867\n",
            "Recall: 0.9961627014581734\n",
            "Precision: 1.0\n",
            "accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CgrrFBcZ90G",
        "outputId": "894bb677-8530-4f70-e369-82a0c8a5beb9"
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  38    0]\n",
            " [  25 6490]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxFvEJ_OxQeb"
      },
      "source": [
        "## KERAS SKLEARN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeBYOO3_sqo_"
      },
      "source": [
        "def create_model(init='random_normal'):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(16, kernel_initializer=init, activation='relu'))\n",
        "  model.add(Dense(16, kernel_initializer=init, activation='relu'))\n",
        "  model.add(Dense(16, kernel_initializer=init, activation='relu'))\n",
        "  model.add(Dense(16, kernel_initializer=init, activation='relu'))\n",
        "  model.add(Dense(16, kernel_initializer=init, activation='relu'))\n",
        "  model.add(Dense(16, kernel_initializer=init, activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer=init, activation='sigmoid'))\n",
        "  define_optimizer = keras.optimizers.Adam(lr = 0.01)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=define_optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        " \n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0, validation_split=0.35)\n",
        "model._estimator_type = \"classifier\"\n",
        "init = ['random_normal']\n",
        "epochs = [350]\n",
        "batches = [15]\n",
        "\n",
        "param_grid = dict(epochs=epochs, batch_size=batches, init=init)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC6pOk7wtNQi",
        "outputId": "ebc32eb8-406f-40e8-e694-104ffa6fcf99"
      },
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "print(means, stds, params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.997660 using {'batch_size': 15, 'epochs': 350, 'init': 'random_normal'}\n",
            "[0.99765997] [0.00051882] [{'batch_size': 15, 'epochs': 350, 'init': 'random_normal'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN8wjVvwv_J5",
        "outputId": "2d93128c-20bd-4f00-c633-70d70c91694f"
      },
      "source": [
        "y_pred = grid_result.predict(X_test)\n",
        "\n",
        "print('Area debajo de la curva:', roc_auc_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('accuracy:', round(accuracy_score(y_test, y_pred), 2))\n",
        "print('')\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Area debajo de la curva: 0.9980813507290867\n",
            "Recall: 0.9961627014581734\n",
            "Precision: 1.0\n",
            "accuracy: 1.0\n",
            "\n",
            "[[  38    0]\n",
            " [  25 6490]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuoKDY-8Bw-Z"
      },
      "source": [
        "### OTHER MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrSeAHM_-L55",
        "outputId": "7c2a5f85-cffb-4e17-e54b-e7b918faca02"
      },
      "source": [
        "tree_model = RandomForestClassifier()\n",
        "\n",
        "param_grid = {'criterion':['gini', 'entropy'], 'max_depth': np.arange(5,15,5), 'min_samples_leaf': np.arange(1,15,10), 'n_estimators': np.arange(5,105,10), 'ccp_alpha':[0.0, 0.1,0.5,0.9, 1]}\n",
        "\n",
        "grid_tree_model = GridSearchCV(tree_model, param_grid, cv = 10)\n",
        "grid_tree_model.fit(X_train.values, y_train.values.ravel())\n",
        "\n",
        "print('Tuned Decision Tree: {}'.format(grid_tree_model.best_params_))\n",
        "print('Tuned accuracy: {}'.format(grid_tree_model.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tuned Decision Tree: {'ccp_alpha': 0.0, 'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 5}\n",
            "Tuned accuracy: 0.9982702894211783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXiXmRfqANvO"
      },
      "source": [
        "y_pred = grid_tree_model.predict(X_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kaJ_c8z6Dy8",
        "outputId": "b3605a71-ed08-403a-8a53-4c71a11c42a8"
      },
      "source": [
        "print('Area debajo de la curva:', roc_auc_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('accuracy:', round(accuracy_score(y_test, y_pred), 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area debajo de la curva: 0.9726865129054408\n",
            "Recall: 0.9980046047582501\n",
            "Precision: 0.9996924969249692\n",
            "accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNSrcmie6Y2D",
        "outputId": "d577dd8c-6777-4c82-dfa6-e755e7493c84"
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  36    2]\n",
            " [  13 6502]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB7c8VvGIUwA"
      },
      "source": [
        "### OTHER XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oe2KKcOIXVp"
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "model_xgb = xgb.XGBClassifier(objective = 'binary:logistic', n_estimators = 105, max_depth=75, seed = 10, reg_alpha=7)\n",
        "model_xgb.fit(X_train.values, y_train.values.ravel())\n",
        "y_pred = model_xgb.predict(X_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-XXskvZfYFs",
        "outputId": "1204ebcc-eb76-4441-c570-64846c7f1961"
      },
      "source": [
        "print('Area debajo de la curva:', roc_auc_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area debajo de la curva: 0.9980813507290867\n",
            "Recall: 0.9961627014581734\n",
            "Precision: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co_bPdAVKvO8",
        "outputId": "11229654-939f-4209-a79f-c94cc3ade8d9"
      },
      "source": [
        "round(accuracy_score(y_test, y_pred), 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7njz4n2zfPbC",
        "outputId": "1e565238-8258-4efc-c0e4-8e7ffba64285"
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  38    0]\n",
            " [  25 6490]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv2B2YQJsXQz"
      },
      "source": [
        "### SKLEARN NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICLmY4zMsZYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f64f5aa-1413-456d-baf3-a82104e7e4f8"
      },
      "source": [
        "nn_class = MLPClassifier()\n",
        "\n",
        "param_grid = {'hidden_layer_sizes':[(8,8,8,8,8,8,8), (16,16,16,16,16,16)], \n",
        "              'activation': ['relu', 'logistic', 'tanh'],\n",
        "              'solver': ['lbfgs', 'adam'],\n",
        "              'max_iter': [800],\n",
        "              'learning_rate': ['constant', 'adaptive']\n",
        "              }\n",
        "\n",
        "grid_nn_class = GridSearchCV(nn_class, param_grid, cv = 10)\n",
        "grid_nn_class.fit(X_train.values, y_train.values.ravel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_stat...\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'activation': ['relu', 'logistic', 'tanh'],\n",
              "                         'hidden_layer_sizes': [(8, 8, 8, 8, 8, 8, 8),\n",
              "                                                (16, 16, 16, 16, 16, 16)],\n",
              "                         'learning_rate': ['constant', 'adaptive'],\n",
              "                         'max_iter': [800], 'solver': ['lbfgs', 'adam']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYordwmcxr1o",
        "outputId": "c0ee2c4c-82c5-4ee2-bef1-7b60b946e70f"
      },
      "source": [
        "print('Tuned Decision Tree: {}'.format(grid_nn_class.best_params_))\n",
        "print('Tuned accuracy: {}'.format(grid_nn_class.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tuned Decision Tree: {'activation': 'tanh', 'hidden_layer_sizes': (8, 8, 8, 8, 8, 8, 8), 'learning_rate': 'constant', 'max_iter': 800, 'solver': 'adam'}\n",
            "Tuned accuracy: 0.9982702894211783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfmrDM51viKP"
      },
      "source": [
        "y_pred = grid_nn_class.predict(X_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNW2MEUbvh7F",
        "outputId": "36ec3230-84e2-4a30-ce71-d86456ea52b3"
      },
      "source": [
        "print('Area debajo de la curva:', roc_auc_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('accuracy:', round(accuracy_score(y_test, y_pred), 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area debajo de la curva: 0.9726865129054408\n",
            "Recall: 0.9980046047582501\n",
            "Precision: 0.9996924969249692\n",
            "accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbCMp8QJ64Mh",
        "outputId": "2fdc8e56-1ff2-45c1-c9fd-3a16a73578e0"
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  36    2]\n",
            " [  13 6502]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdirOuaDx12A"
      },
      "source": [
        "### VOTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_phVMXRmyjc",
        "outputId": "d18f14c4-04fc-48af-842f-b6db7ab68369"
      },
      "source": [
        "client = 'someclient'\n",
        "\n",
        "model_classifier.save(\"model.h5\") # keras\n",
        "\n",
        "joblib.dump(model_xgb, 'xgboost_tree' + client +'.pkl') #xgboost\n",
        "joblib.dump(grid_tree_model, 'sklearn_tree' + client +'.pkl') #sklearn\n",
        "joblib.dump(grid_nn_class, 'sklearn_nn'+ client +'.pkl') #sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sklearn_nnfedex.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmrOwG7Eu4qX"
      },
      "source": [
        "_, _, filenames = next(walk('/content'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}